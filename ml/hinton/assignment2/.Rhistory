?rnorm
?sample
runif(1)
?rnorm
?runif
}
source('~/prog/alexeyche-junk/ml/stat_anal/1.R')
?rnorm
?sample
sample(c(1,2,3),2)
0.9*15
tail(0.9*15)
floor(0.9*15)
ceil(0.9*15)
ceiling(0.9*15)
source('~/.active-rstudio-document')
x
hist(x)
source('~/prog/alexeyche-junk/ml/stat_anal/1.R')
hist(y)
source('~/prog/alexeyche-junk/ml/stat_anal/1.R')
x
plot(x)
hist(x)
?t.test
break
source('~/prog/alexeyche-junk/ml/hinton/assignment2/train.R')
d <- readMat("data.mat")
d <- d$data[,,]
numdims <- nrow(d$trainData)
D <- numdims - 1
M <- floor(ncol(d$trainData)/N)
train_input <- array(d$trainData[1:D,1:(N*M)], dim=c(D,N,M))
train_target <- array(d$trainData[D+1,1:(N*M)], dim=c(1,N,M))
valid_input <- d$validData[1:D,]
valid_target <- d$validData[D+1,]
test_input <- d$testData[1:D,]
test_target <- d$testData[D+1,]
vocab <- NULL
for(i in 1:length(d$vocab)) {
vocab <- rbind(vocab, d$vocab[[i]])
}
library(R.matlab)
library(R.matlab)
d <- readMat("data.mat")
d <- d$data[,,]
numdims <- nrow(d$trainData)
D <- numdims - 1
M <- floor(ncol(d$trainData)/N)
train_input <- array(d$trainData[1:D,1:(N*M)], dim=c(D,N,M))
train_target <- array(d$trainData[D+1,1:(N*M)], dim=c(1,N,M))
valid_input <- d$validData[1:D,]
valid_target <- d$validData[D+1,]
test_input <- d$testData[1:D,]
test_target <- d$testData[D+1,]
vocab <- NULL
for(i in 1:length(d$vocab)) {
vocab <- rbind(vocab, d$vocab[[i]])
}
setwd("~/prog/alexeyche-junk/ml/hinton/assignment2")
d <- readMat("data.mat")
d <- d$data[,,]
numdims <- nrow(d$trainData)
D <- numdims - 1
M <- floor(ncol(d$trainData)/N)
train_input <- array(d$trainData[1:D,1:(N*M)], dim=c(D,N,M))
train_target <- array(d$trainData[D+1,1:(N*M)], dim=c(1,N,M))
valid_input <- d$validData[1:D,]
valid_target <- d$validData[D+1,]
test_input <- d$testData[1:D,]
test_target <- d$testData[D+1,]
vocab <- NULL
for(i in 1:length(d$vocab)) {
vocab <- rbind(vocab, d$vocab[[i]])
}
View(test_input)
View(test_input)
fix(d)
View(vocab)
source('sys.R')  # := notation
source('load_data.R')
source('fprop.R')
source('sys.R')  # := notation
source('load_data.R')
source('fprop.R')
epochs <- 100
# SET HYPERPARAMETERS HERE.
batchsize <- 100  # Mini-batch size.
learning_rate <- 0.1  # Learning rate default <- 0.1.
momentum <- 0.9  # Momentum default <- 0.9.
numhid1 <- 50  # Dimensionality of embedding space default <- 50.
numhid2 <- 200  # Number of units in hidden layer default <- 200.
init_wt <- 0.01  # Standard deviation of the normal distribution
# which is sampled to get the initial weights default = 0.01
# VARIABLES FOR TRACKING TRAINING PROGRESS.
show_training_CE_after <- 100
show_validation_CE_after <- 1000
# LOAD DATA
c(train_input, train_target, valid_input, valid_target, test_input, test_target, vocab) := load_data(batchsize)
c(numwords, batchsize, numbatches) := dim(train_input)
vocab_size <- nrow(vocab)
# INITIALIZE WEIGHTS AND BIASES.
word_embedding_weights <- init_wt * matrix(rnorm(vocab_size*numhid1), vocab_size, numhid1) #randn(vocab_size, numhid1)
embed_to_hid_weights <- init_wt * matrix( rnorm(numwords * numhid1 * numhid2), numwords * numhid1, numhid2) #randn(numwords * numhid1, numhid2)
hid_to_output_weights <- init_wt * matrix(rnorm(numhid2 * vocab_size), numhid2, vocab_size) #randn(numhid2, vocab_size)
hid_bias <- matrix(0, numhid2, 1) #zeros(numhid2, 1)
output_bias <- matrix(0, vocab_size, 1) #zeros(vocab_size, 1)
word_embedding_weights_delta <- matrix(0, vocab_size, numhid1)
word_embedding_weights_gradient <- matrix(0, vocab_size, numhid1)
embed_to_hid_weights_delta <- matrix(0, numwords * numhid1, numhid2)
hid_to_output_weights_delta <- matrix(0, numhid2, vocab_size)
hid_bias_delta <- matrix(0, numhid2, 1)
output_bias_delta <- matrix(0, vocab_size, 1)
expansion_matrix <- diag(1, vocab_size)
count <- 0
tiny <- exp(-30)
for(epoch in 1:epochs) {
cat("Epoch num: ", epoch, "\n")
this_chunk_CE <- 0
trainset_CE <- 0
# LOOP OVER MINI-BATCHES.
for(m in 1:numbatches) {
input_batch <- train_input[,,m]
target_batch <- train_target[,,m]
# FORWARD PROPAGATE.
# Compute the state of each layer in the network given the input batch
# and all weights and biases
c(embedding_layer_state, hidden_layer_state, output_layer_state) := fprop(input_batch, word_embedding_weights, embed_to_hid_weights,
hid_to_output_weights, hid_bias, output_bias);
break
}
break
}
View(input_batch)
View(word_embedding_weights)
c(vocab_size, numhid1) := dim(word_embedding_weights)
numhid1
numhid2
input_batch
t(input_batch)
cbind(t(input_batch))
as.vector(input_batch)
View(input_batch)
word_embedding_weights(as.vector(input_batch),)
word_embedding_weights[as.vector(input_batch),]
word_embedding_weights[as.vector(input_batch),1]
word_embedding_weights[as.vector(input_batch),]
as.vector(input_batch)
word_embedding_weights[28,1]
View(word_embedding_weights)
word_embedding_weights[(c(28,26,90),1]
word_embedding_weights[c(28,26,90),1]
word_embedding_weights[c(28,26,90),2]
word_embedding_weights[c(28,26,90),]
t(word_embedding_weights[c(28,26,90),])
t(word_embedding_weights[c(28,26,90,100),])
t(word_embedding_weights[c(28,26,90,100,101),])
t(word_embedding_weights[c(28,26,90,100,101,102),])
matrix(t(word_embedding_weights[c(28,26,90,100,101,102),]), nrow = numhid1*numwords)
matrix(t(word_embedding_weights[c(28,26,90),]), nrow = numhid1*numwords)
matrix(t(word_embedding_weights[c(28,26,90),]), nrow = 3*numwords)
matrix(t(word_embedding_weights[c(28,26,90),]), nrow = 1*numwords)
matrix(t(word_embedding_weights[c(28,26,90),]), nrow = numhid1*numwords)
embedding_layer_state = matrix(t(word_embedding_weights[as.vector(input_batch),]), nrow = numhid1 * numwords)
View(embedding_layer_state)
View(embed_to_hid_weights)
t(embed_to_hid_weights) %*% embedding_layer_state
str(t(embed_to_hid_weights) %*% embedding_layer_state)
View(hid_bias)
rep(hid_bias)
rep(hid_bias,2)
matrix(rep(hid_bias,nrow=200)
matrix(rep(hid_bias,nrow=200))
matrix(rep(hid_bias,nrow=200),3)
matrix(rep(hid_bias,3),nrow=200)
inputs_to_hidden_units <- t(embed_to_hid_weights) %*% embedding_layer_state + matrix(rep(hid_bias,batchsize),nrow=numhid2)
View(inputs_to_hidden_units)
(1 + exp(-inputs_to_hidden_units))
1/(1 + exp(-inputs_to_hidden_units))
str(1/(1 + exp(-inputs_to_hidden_units)))
hidden_layer_state <- 1 / (1 + exp(-inputs_to_hidden_units))
inputs_to_softmax = t(hid_to_output_weights) %*% hidden_layer_state
View(inputs_to_softmax)
View(inputs_to_softmax)
max(inputs_to_softmax)
View(inputs_to_softmax)
maxRow
str(apply(inputs_to_softmax,2,max)
str(apply(inputs_to_softmax,2,max))
View(inputs_to_softmax)
inputs_to_softmax <- inputs_to_softmax - apply(inputs_to_softmax,2,max)
exp(inputs_to_softmax)
output_layer_state <- exp(inputs_to_softmax)
View(output_layer_state)
str(apply(output_layer_state,2,sum))
str(rep(apply(output_layer_state,2,sum),vocab_size))
matrix(str(rep(apply(output_layer_state,2,sum),vocab_size)), nrow = batchsize)
str(matrix(rep(apply(output_layer_state,2,sum),vocab_size), nrow = batchsize))
temp <- matrix(rep(apply(output_layer_state,2,sum),vocab_size), nrow = batchsize)
View(temp)
temp <- output_layer_state/temp
temp <- apply(output_layer_state,2,sum),vocab_size)
temp <- apply(output_layer_state,2,sum)
fix(temp)
temp <- matrix(rep(apply(output_layer_state,2,sum),vocab_size), nrow = batchsize)
View(temp)
batchsize
dim(output_layer_state)
temp <- matrix(rep(apply(output_layer_state,2,sum),vocab_size), nrow = vocab_size)
View(temp)
temp <- output_layer_state/temp
View(temp)
output_layer_state <- output_layer_state / matrix(rep(apply(output_layer_state,2,sum),vocab_size), nrow = vocab_size)
View(output_layer_state)
source('~/prog/alexeyche-junk/ml/hinton/assignment2/train.R', echo=TRUE)
View(embedding_layer_state)
View(output_layer_state)
source('~/prog/alexeyche-junk/ml/hinton/assignment2/train.R', echo=TRUE)
View(output_layer_state)
View(expansion_matrix)
source('~/.active-rstudio-document', echo=TRUE)
source('~/prog/alexeyche-junk/ml/hinton/assignment2/train.R', echo=TRUE)
View(expanded_target_batch)
View(error_deriv)
fix(target_batch)
expanded_target_batch * log(output_layer_state + tiny))
expanded_target_batch * log(output_layer_state + tiny)
temp <- expanded_target_batch * log(output_layer_state + tiny)
View(temp)
sum(temp)
-sum(temp)/batchsize
?mod
source('~/prog/alexeyche-junk/ml/hinton/assignment2/train.R', echo=TRUE)
source('~/prog/alexeyche-junk/ml/hinton/assignment2/train.R', echo=TRUE)
View(output_layer_state)
View(error_deriv)
View(expanded_target_batch)
