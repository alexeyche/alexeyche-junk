gr1$loadPatterns(train_dataset, duration, dt, lambda=5)
patt <- list(pattDur=pattDur, dt=pattDur/length(rawdata), rawdata=rawdata, len=length(rawdata), label=label)
if(is.null(hb)) hb <- max(rawdata)
if(is.null(lb)) lb <- min(rawdata)
patt_dt <- 0
approx_data = rep(NA, pattDur/simdt)
for(ri in 1:patt$len) {
patt_dt <- patt_dt + pattDur/patt$len
ct = ceiling(signif(patt_dt/simdt, digits=5))
approx_data[ct] = rawdata[ri]
}
approx_data = approx_data[approx_data != NA]
approx_data
approx_data = rep(NA, pattDur/simdt)
for(ri in 1:patt$len) {
patt_dt <- patt_dt + pattDur/patt$len
ct = ceiling(signif(patt_dt/simdt, digits=5))
approx_data[ct] = rawdata[ri]
}
approx_data
pattDur
length(approx_data)
patt <- list(pattDur=pattDur, dt=pattDur/length(rawdata), rawdata=rawdata, len=length(rawdata), label=label)
if(is.null(hb)) hb <- max(rawdata)
if(is.null(lb)) lb <- min(rawdata)
patt_dt <- 0
approx_data = rep(NA, pattDur/simdt)
for(ri in 1:patt$len) {
patt_dt <- patt_dt + pattDur/patt$len
ct = ceiling(signif(patt_dt/simdt, digits=5))
approx_data[ct] = rawdata[ri]
}
approx_data
length(approx_data)
approx_data = approx_data[approx_data != NA]
approx_data
patt <- list(pattDur=pattDur, dt=pattDur/length(rawdata), rawdata=rawdata, len=length(rawdata), label=label)
if(is.null(hb)) hb <- max(rawdata)
if(is.null(lb)) lb <- min(rawdata)
patt_dt <- 0
approx_data = rep(NA, pattDur/simdt)
for(ri in 1:patt$len) {
patt_dt <- patt_dt + pattDur/patt$len
ct = ceiling(signif(patt_dt/simdt, digits=5))
approx_data[ct] = rawdata[ri]
}
patt <- list(pattDur=pattDur, dt=pattDur/length(rawdata), rawdata=rawdata, len=length(rawdata), label=label)
if(is.null(hb)) hb <- max(rawdata)
if(is.null(lb)) lb <- min(rawdata)
patt_dt <- 0
approx_data = rep(NA, pattDur/simdt)
for(ri in 1:patt$len) {
patt_dt <- patt_dt + pattDur/patt$len
ct = ceiling(signif(patt_dt/simdt, digits=5))
approx_data[ct] = rawdata[ri]
}
approx_data
approx_data != NA
is.na(approx_data )
source('~/my/git/alexeyche-junk/cns/R/srm/new/gen_spikes.R', echo=TRUE)
setwd("~/my/git/alexeyche-junk/cns/R/srm/new")
#setwd("~/prog/alexeyche-junk/cns/R/srm/new")
dir = '~/my/sim'
#dir = '~/prog/sim'
system(sprintf("find %s/R -name \"*.png\" -type f -exec rm -f {} \\;", dir))
source('util.R')
source('plot_funcs.R')
source('ucr_ts.R')
source('gen_spikes.R')
source('neuron.R')
source('target_functions.R')
source('learn_and_run_net.R')
source('srm.R')
source('grad_funcs.R')
source('serialize_to_bin.R')
ID_MAX=0
#require(snowfall)
#if(!sfIsRunning()) {
#  sfInit(parallel=TRUE, cpus=10)
#  res = sfClusterEval(require('snnSRM'))
#}
#sfExport('constants')
data = synth # synthetic control
if(!exists('train_dataset')) {
c(train_dataset, test_dataset) := read_ts_file(data)
}
#train_dataset = train_dataset[c(1,101, 2, 102, 3, 103, 4, 104, 5, 105)] # cut
duration = 200
N = 10
start_w = 2.0
M = 50
dt = 0.5
start_w.M = 4 #matrix(rnorm( M*N, mean=2, sd=0.5), ncol=N, nrow=M)
start_w.N = 4 #matrix(rnorm( (N-1)*N, mean=2, sd=0.5), ncol=N, nrow=(N-1))
gr1 = TSNeurons(M = M)
neurons = SRMLayer(N, start_w.N, p_edge_prob=0.5)
gr1$loadPatterns(train_dataset, duration, dt, lambda=5)
plot_rastl(gr1$patterns[[1]]$data)
plot_rastl(gr1$patterns[[51]]$data)
gr1$patterns[[51]]$data
patt <- list(pattDur=pattDur, dt=pattDur/length(rawdata), rawdata=rawdata, len=length(rawdata), label=label)
if(is.null(hb)) hb <- max(rawdata)
if(is.null(lb)) lb <- min(rawdata)
patt_dt <- 0
approx_data = rep(NA, pattDur/simdt)
for(ri in 1:patt$len) {
patt_dt <- patt_dt + pattDur/patt$len
ct = ceiling(signif(patt_dt/simdt, digits=5))
approx_data[ct] = rawdata[ri]
}
#approx_data = na.approx(approx_data)
approx_data = approx_data[!is.na(approx_data)]
approx_data
gen_spikes = vector("list", M)
neurons_rate = rep(0, M)
dt <- (hb-lb)/(M-1)
t = 0
i_val=1
fired <- floor((approx_data[i_val]-lb)/dt)+1
fired
source('~/my/git/alexeyche-junk/cns/R/srm/new/gen_spikes.R', echo=TRUE)
setwd("~/my/git/alexeyche-junk/cns/R/srm/new")
#setwd("~/prog/alexeyche-junk/cns/R/srm/new")
dir = '~/my/sim'
#dir = '~/prog/sim'
system(sprintf("find %s/R -name \"*.png\" -type f -exec rm -f {} \\;", dir))
source('util.R')
source('plot_funcs.R')
source('ucr_ts.R')
source('gen_spikes.R')
source('neuron.R')
source('target_functions.R')
source('learn_and_run_net.R')
source('srm.R')
source('grad_funcs.R')
source('serialize_to_bin.R')
ID_MAX=0
#require(snowfall)
#if(!sfIsRunning()) {
#  sfInit(parallel=TRUE, cpus=10)
#  res = sfClusterEval(require('snnSRM'))
#}
#sfExport('constants')
data = synth # synthetic control
if(!exists('train_dataset')) {
c(train_dataset, test_dataset) := read_ts_file(data)
}
#train_dataset = train_dataset[c(1,101, 2, 102, 3, 103, 4, 104, 5, 105)] # cut
duration = 200
N = 10
start_w = 2.0
M = 50
dt = 0.5
start_w.M = 4 #matrix(rnorm( M*N, mean=2, sd=0.5), ncol=N, nrow=M)
start_w.N = 4 #matrix(rnorm( (N-1)*N, mean=2, sd=0.5), ncol=N, nrow=(N-1))
gr1 = TSNeurons(M = M)
neurons = SRMLayer(N, start_w.N, p_edge_prob=0.5)
gr1$loadPatterns(train_dataset, duration, dt, lambda=5)
patt_len = length(gr1$patterns)
source('~/my/git/alexeyche-junk/cns/R/srm/new/gen_spikes.R', echo=TRUE)
setwd("~/my/git/alexeyche-junk/cns/R/srm/new")
#setwd("~/prog/alexeyche-junk/cns/R/srm/new")
dir = '~/my/sim'
#dir = '~/prog/sim'
system(sprintf("find %s/R -name \"*.png\" -type f -exec rm -f {} \\;", dir))
source('util.R')
source('plot_funcs.R')
source('ucr_ts.R')
source('gen_spikes.R')
source('neuron.R')
source('target_functions.R')
source('learn_and_run_net.R')
source('srm.R')
source('grad_funcs.R')
source('serialize_to_bin.R')
ID_MAX=0
#require(snowfall)
#if(!sfIsRunning()) {
#  sfInit(parallel=TRUE, cpus=10)
#  res = sfClusterEval(require('snnSRM'))
#}
#sfExport('constants')
data = synth # synthetic control
if(!exists('train_dataset')) {
c(train_dataset, test_dataset) := read_ts_file(data)
}
#train_dataset = train_dataset[c(1,101, 2, 102, 3, 103, 4, 104, 5, 105)] # cut
duration = 200
N = 10
start_w = 2.0
M = 50
dt = 0.5
start_w.M = 4 #matrix(rnorm( M*N, mean=2, sd=0.5), ncol=N, nrow=M)
start_w.N = 4 #matrix(rnorm( (N-1)*N, mean=2, sd=0.5), ncol=N, nrow=(N-1))
gr1 = TSNeurons(M = M)
neurons = SRMLayer(N, start_w.N, p_edge_prob=0.5)
gr1$loadPatterns(train_dataset, duration, dt, lambda=5)
patt_len = length(gr1$patterns)
plot_rastl(gr1$patterns[[51]]$data)
plot_rastl(gr1$patterns[[1]]$data)
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
setwd("~/my/git/alexeyche-junk/cns/R/srm/new")
#setwd("~/prog/alexeyche-junk/cns/R/srm/new")
dir = '~/my/sim'
#dir = '~/prog/sim'
system(sprintf("find %s/R -name \"*.png\" -type f -exec rm -f {} \\;", dir))
source('util.R')
source('plot_funcs.R')
source('ucr_ts.R')
source('gen_spikes.R')
source('neuron.R')
source('target_functions.R')
source('learn_and_run_net.R')
source('srm.R')
source('grad_funcs.R')
source('serialize_to_bin.R')
ID_MAX=0
#require(snowfall)
#if(!sfIsRunning()) {
#  sfInit(parallel=TRUE, cpus=10)
#  res = sfClusterEval(require('snnSRM'))
#}
#sfExport('constants')
data = synth # synthetic control
if(!exists('train_dataset')) {
c(train_dataset, test_dataset) := read_ts_file(data)
}
#train_dataset = train_dataset[c(1,101, 2, 102, 3, 103, 4, 104, 5, 105)] # cut
duration = 200
N = 10
start_w = 2.0
M = 50
dt = 0.5
start_w.M = 4 #matrix(rnorm( M*N, mean=2, sd=0.5), ncol=N, nrow=M)
start_w.N = 4 #matrix(rnorm( (N-1)*N, mean=2, sd=0.5), ncol=N, nrow=(N-1))
gr1 = TSNeurons(M = M)
neurons = SRMLayer(N, start_w.N, p_edge_prob=0.5)
gr1$loadPatterns(train_dataset, duration, dt, lambda=5)
patt_len = length(gr1$patterns)
#gr1$patterns = gr1$patterns[sample(patt_len)]
#plot_rastl(gr1$patterns[[3]]$data)
connection = matrix(gr1$ids, nrow=length(gr1$ids), ncol=N)
connect_window = N*2
step = M/N
overlap = 1
for(ni in 0:(N-1)) {
if(ni != 0) connection[1:((ni*step)-overlap),ni+1] = 0
if(ni != N-1) connection[((ni*step)+step+1+overlap):M,ni+1] = 0
}
neurons$connectFF(connection, start_w.M, 1:N )
runmode="learn"
#runmode="run"
run_options = list(T0 = 0, Tmax = duration, dt = dt, learning_rate = 0.01, epochs = 25,
learn_window_size = 100, mode=runmode, collect_stat=TRUE,
target_set = list(target_function_gen = random_4spikes_tf, depress_null=FALSE),
learn_layer_id = 1
)
ro = run_options # for debug
id_patt = 1
#model_file = sprintf("%s/R/%s_%dx%d_lr%3.1f_lws_%3.1f", dir, data, M, N, run_options$learning_rate, run_options$learn_window_size)
model_file = sprintf("%s/R/%s_%dx%d", dir, data, M, N)
if(runmode=="run") {
if(file.exists(paste(model_file, ".idx", sep=""))) {
W = loadMatrix(model_file, 1)
invisible(sapply(1:(N), function(id) {
neurons$weights[[id]] = W[1:length(neurons$id_conns[[id]]),id]
}
))
} else {
cat("Can't find file for model ", model_file, "\n")
}
}
patterns = gr1$patterns
layers = list(gr1, neurons)
input_neurons = layers[[1]]
net_neurons = layers[2:length(layers)]
patterns = input_neurons$patterns
lengths = sapply(patterns, function(p) length(p$data))
stopifnot(all(lengths == lengths[1]))
id_m = input_neurons$ids
id_n = c(sapply(layers[2:length(layers)], function(n) n$ids))
net = list()
net[id_m] = patterns[[1]]$data
net[id_n] = -Inf
run_options$target_set$class = patterns[[id_patt]]$class
net[id_m] = patterns[[id_patt]]$data
net[id_n] = -Inf
run_options$target_set$class = patterns[[id_patt]]$class
N = net_neurons[[1]]$len
if(ro$collect_stat) {
uum = NULL # for stat collecting
ppm = NULL
gr_it = 1
maxw_len = 0
invisible(sapply(1:net_neurons[[ro$learn_layer_id]]$len, function(n_id) maxw_len<<-max(maxw_len, length(net_neurons[[ro$learn_layer_id]]$weights[[n_id]]))))
gradients = array(0, dim=c(maxw_len, net_neurons[[ro$learn_layer_id]]$len, ro$Tmax %/% ro$learn_window_size))
}
stat = list()
for(i in 1:length(net_neurons)) {
stat[[i]] = list()
stat[[i]]$p = NULL
stat[[i]]$u = NULL
}
T = seq(ro$T0, ro$Tmax, by=ro$dt)
T
ro$Tmax=100
N = net_neurons[[1]]$len
if(ro$collect_stat) {
uum = NULL # for stat collecting
ppm = NULL
gr_it = 1
maxw_len = 0
invisible(sapply(1:net_neurons[[ro$learn_layer_id]]$len, function(n_id) maxw_len<<-max(maxw_len, length(net_neurons[[ro$learn_layer_id]]$weights[[n_id]]))))
gradients = array(0, dim=c(maxw_len, net_neurons[[ro$learn_layer_id]]$len, ro$Tmax %/% ro$learn_window_size))
}
stat = list()
for(i in 1:length(net_neurons)) {
stat[[i]] = list()
stat[[i]]$p = NULL
stat[[i]]$u = NULL
}
T = seq(ro$T0, ro$Tmax, by=ro$dt)
for(time in T) {
i=1
for(neurons in net_neurons) {
uu = neurons$u(time, net)
pp = g(uu)
fired = pp*ro$dt>runif(neurons$len)
idf = neurons$ids[fired]
#cat("pp" = pp, " idf=", idf, " uu=", uu, " fired=",fired, "\n", sep="")
for(id in idf) {
net[[id]] <- c(net[[id]], time)
#cat("t: ", time, " spike of ", id, "\n")
}
if(ro$collect_stat) {
stat[[i]]$p = rbind(stat[[i]]$p, pp)
stat[[i]]$u = rbind(stat[[i]]$u, c(uu))
}
i=i+1
}
}
id_n = neurons$ids #sapply(neurons, function(n) n$id)
nspikes = lapply(net[id_n], function(sp) {
left = findInterval(T0, sp)+1
right = findInterval(Tmax, sp, rightmost.closed=TRUE)
if(left<=right) sp[left:right]
})
T0=0
Tmax=100
id_n = neurons$ids #sapply(neurons, function(n) n$id)
nspikes = lapply(net[id_n], function(sp) {
left = findInterval(T0, sp)+1
right = findInterval(Tmax, sp, rightmost.closed=TRUE)
if(left<=right) sp[left:right]
})
nspikes
if(sum(sapply(nspikes, length)/(Tmax-T0)) > 0.6) {
nspikes = lapply(1:length(id_n), function(ni) {
if(!is.null(nspikes[[ni]])) {
probs = g(neurons$u_one(ni, nspikes[[ni]], net))
most_likely = probs>=mean(probs)
nspikes[[ni]][most_likely]
}
})
}
nspikes
left_part = lapply(1:length(id_n), function(number) {
if(!is.null(nspikes[[number]])) {
u = neurons$u_one(number, nspikes[[number]], net)
#cat("n(", neurons[[number]]$id, ")u=",u,"\n")
ans = (p_stroke(u)/g(u))
ans[ans>5] = 5
return(ans)
}
})
spike_part = lapply(1:length(id_n), function(id_number) {
sapply(neurons$id_conns[[id_number]], function(idc) {
if(!is.null(nspikes[[id_number]])) {
sum(left_part[[id_number]]*grab_epsp(nspikes[[id_number]], net[[idc]]))
} else {
0
}
})
})
spike_part
net
if(!target_set$depress_null) {
not_fired = sapply(nspikes, is.null)
} else {
not_fired = rep(FALSE, neurons$len)
}
int_options = list(T0 = T0, Tmax=Tmax, dim=sum(sapply(neurons$id_conns, length)), quad=256)
target_set = ro$target_set
if(!target_set$depress_null) {
not_fired = sapply(nspikes, is.null)
} else {
not_fired = rep(FALSE, neurons$len)
}
int_options = list(T0 = T0, Tmax=Tmax, dim=sum(sapply(neurons$id_conns, length)), quad=256)
not_fired
grad = integrateSRM_vec(constants, int_options, neurons$ids, neurons$id_conns, neurons$weights, net)$out
grad
neurons$weights
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
source('~/my/git/alexeyche-junk/cns/R/srm/new/main_ucr.R', echo=TRUE)
intstall.packages('entropy')
insttall.packages('entropy')
install.packages('entropy')
require(entropy)
?entropy
y = c(4, 2, 3, 0, 2, 4, 0, 0, 2, 1, 1)
entropy(y, method="ML")
x1 = runif(10000)
dicretize(x1, numBins=10, r=c(0,1))
discretize(x1, numBins=10, r=c(0,1))
entropy(discretize(x1, numBins=10, r=c(0,1)))
x1 = runif(10000)
x2 = runif(10000)
y2d = discretize2d(x1, x2, numBins1=10, numBins2=10)
y2d
mi.empirical(y2d)
sum(y2d)
log(10)
?entropy
install.packages('np')
?np
require(np)
?np
?entropy
density
density(y)
y
density(y)
?density
plot(d)
d = density(y)
plot(d)
y
d
d[2]
?density
model_file
model_file = sprintf("%s/R/%s_%dx%d", dir, data, M, N)
setwd("~/my/git/alexeyche-junk/cns/R/srm/new")
#setwd("~/prog/alexeyche-junk/cns/R/srm/new")
dir = '~/my/sim'
#dir = '~/prog/sim'
system(sprintf("find %s/R -name \"*.png\" -type f -exec rm -f {} \\;", dir))
source('util.R')
source('plot_funcs.R')
source('ucr_ts.R')
source('gen_spikes.R')
source('neuron.R')
source('target_functions.R')
source('learn_and_run_net.R')
source('srm.R')
source('grad_funcs.R')
source('serialize_to_bin.R')
ID_MAX=0
#require(snowfall)
#if(!sfIsRunning()) {
#  sfInit(parallel=TRUE, cpus=10)
#  res = sfClusterEval(require('snnSRM'))
#}
#sfExport('constants')
data = synth # synthetic control
if(!exists('train_dataset')) {
c(train_dataset, test_dataset) := read_ts_file(data)
}
#train_dataset = train_dataset[c(1,101, 2, 102, 3, 103, 4, 104, 5, 105)] # cut
duration = 300
N = 10
start_w = 2.0
M = 50
dt = 0.5
start_w.M = 10 #matrix(rnorm( M*N, mean=2, sd=0.5), ncol=N, nrow=M)
start_w.N = 6 #matrix(rnorm( (N-1)*N, mean=2, sd=0.5), ncol=N, nrow=(N-1))
gr1 = TSNeurons(M = M)
neurons = SRMLayer(N, start_w.N, p_edge_prob=0.5)
gr1$loadPatterns(train_dataset, duration, dt, lambda=5)
patt_len = length(gr1$patterns)
gr1$patterns = gr1$patterns[sample(patt_len)]
#plot_rastl(gr1$patterns[[3]]$data)
connection = matrix(gr1$ids, nrow=length(gr1$ids), ncol=N)
connect_window = N*2
step = M/N
overlap = 1
for(ni in 0:(N-1)) {
if(ni != 0) connection[1:((ni*step)-overlap),ni+1] = 0
if(ni != N-1) connection[((ni*step)+step+1+overlap):M,ni+1] = 0
}
neurons$connectFF(connection, start_w.M, 1:N )
runmode="learn"
#runmode="run"
run_options = list(T0 = 0, Tmax = duration, dt = dt, learning_rate = 0.01, epochs = 25,
learn_window_size = 100, mode=runmode, collect_stat=TRUE,
target_set = list(target_function_gen = random_4spikes_tf, depress_null=FALSE),
learn_layer_id = 1
)
ro = run_options # for debug
id_patt = 1
#model_file = sprintf("%s/R/%s_%dx%d_lr%3.1f_lws_%3.1f", dir, data, M, N, run_options$learning_rate, run_options$learn_window_size)
model_file = sprintf("%s/R/%s_%dx%d", dir, data, M, N)
model_file = sprintf("%s/R/%s_%dx%d", dir, data, M, N)
model_file
