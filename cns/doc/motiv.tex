\documentclass[a4paper,10pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{ucs}
\usepackage{cmap}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{color,graphicx}
\title{Заголовок}
\author{Автор}
\begin{document}

\section*{Вводные слова}
\indent
\indent Основная задача будущего исследования - создать унифицированный подход в использовании возможностей сложных динамических нейроннных систем в проблемах обработки больших объемов данных и осуществления при помощи них классических задач машинного обучения таких как кластеризация, регрессия, классификация.\\
\indent Динамические системы вдохновленные структурой коры головного мозга давно являются, как минимум, любопытным феноменом для учёных. Мозг является сложным многосистемным вычислительным устройством, который поражает своими вычислительными способностями и подчерпнуть хоть немного из его строения, научиться это использовать, является большим вызовом.\\

\section*{Нейронные сети}
\indent
\indent Первое поколение Искусственных Нейронных Сетей (ИНС) взяло только основные принципы работы биологических нейросетей. В них нейрон формализован как сумматор принимающий на вход сигналы от других нейронов и на основе искусственно введенной нелинейности решает передавать сигнал дальше или нет.\\
\indent Вторым поколением ИНС можно назвать модели школы Хинтона. Эти модели имеют стохастическую природу - нейрон передает или не передает сигнал в зависимости от вероятности выражаемой через коэффициенты модели, которые обучаются на данных без учителя.\\ 
\indent Обучение без учителя является ключевым показателем интеллектуальности алгоритма. Интеллект сам по себе, как свойство живых организмов, представляет собой следствие самоорганизации природы в определенных условиях. Руководствуясь подобными предпосылками, на базе школы Хинтона выросло направление в Machine Learning - Representation Learning.\\
\indent Representation Learning собрал для себя следующие принципы, которые, по большей части, взяты именно из особенностей работы мозга: 
\begin{itemize}
\item распределенность хранения (distributed representation);
\item разреженность представления (sparse code);
\item генеративные модели (generative models);
\end{itemize}
Общий тренд развития интеллектуальных алгоритмов стремительно идёт по направлению к биоподобным моделям.

\section*{Паралелли с Neuroscience}
\indent
\indent Neuroscience, как наука, за последние 50 лет накопила множество опыта в исследовании особенностей функционирования мозга. Computational Neuroscience серьезно продвинулся в моделировании биологических процессов, начиная со знаменитой работы Hodkin и Huxley в моделировании нейрона кальмара, заканчивая масштабными симуляциями нейронной активности (порядка 10^4 нейронов).
\indent В отличии от Neuroscience данная работа не ставит целью воспроизвести биологические процессы, но создать подход в применении таких моделей для конкретных информационных задач.

\section*{Предпосылки и мотивация применения биологических моделей}

\end{document}
