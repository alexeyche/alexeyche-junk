\documentclass[a4paper,10pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage{ucs}
\usepackage{cmap}
\usepackage[english,russian]{babel}
\usepackage{amsmath}
\usepackage{color,graphicx}
\usepackage{indentfirst}
\usepackage{ucs} 
\usepackage[utf8x]{inputenc}

\title{Обзор спайковых сетей}
\author{Чернышев Алексей}
\setlength{\parindent}{1cm}
\def\la{\left\langle\rule{0pt}{3em}}
\def\ra{\right\rangle}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}



\begin{document}
\input{./review_title.tex}

\tableofcontents
\clearpage
\section{Введение}
	\indent За последние сто лет биологические исследования накопили огромное количество детализированных знаний о нюансах функционирования мозга. В качестве структурной единицы центральной нервной системы, рассматривается клетка - нейрон, соединение которых в огромные формирования характеризует сложное  устройство нервных систем.\\
	\indent Не смотря на разнообразие типов нейронов, которые накопила нейронаука, можно выделить основные харкактеристики биологического нейрона:
	\begin{enumerate}
	\item нейрон, заряженная частица, заряд которой поддерживается балансом между концентрацией ионов солей внутри клетки и снаружи
	\item динамику нейрона можно свести к стадии накопления потенциала и стадии выработки короткого импульса	 (спайка)
	\item нейроны соединяются между собой синапсами, которые проводят спайки к другому нейрону (или дендриту нейрона)
	\item после выработки спайка из-за закрытия определённых ионных каналов, нейрон некоторое время не чувствителен к входным спайкам (состояние рефракторности)
	\item в нейроне, также как и во многих других клетках, существует феномен адаптации, т.е. динамика нейрона начинает угасать (привыкать) к одному и тому же стимулу
	\end{enumerate}
	Нейрон, в первую очередь, интересен своими возможностями по обработке информации и, до сих пор, важной является проблема выделения тех самых необходимых свойств биологического нейрона, моделирование которых поможет найти лучшее решения в сложных интеллектульных и перцептивных задачах.\\
	\indent В данном обзоре рассматриваются ряд нейронных моделей, каждая из которых несет в себе ту или иную степень биоподобности. Рассматриваются достоинства и недостатки таких моделей в контексте решения задач машинного обучения.

\section{Нейронные модели}
\subsection{Общие модели}
В данной секции рассматриваются модели, которые по тем или иным причинам не пригодны для моделирования спайковых нейронных сетей
\subsubsection{Нейрон МакКалока-Питтса}
   Первая модель нейрона, положившая начало нейроинформатике  - модель МакКаллока-Питтса. Эта модель прочно заложила фундамент теории нейронных сетей, и исследования новых свойств этой модели не   прекращаются по сей день.\\
   \indent Впервые, была реализована идея использовать нейрон, как вычислительный элемент. Раннее развитие данного направления в основном характеризуется попыткой рассмотреть нейроны, как элементы,        реализующие простейшие логические операции или преобразования. Впоследствии были созданы более сложные схемы, в которых данный нейрон соединяется в сети.\\
   \indent Ключевой особенностью данной модели является то, что нейрон представляется, как взвешенный сумматор входных скалярных признаков $x_{1},$ $x_{2},...,x_{n}$. Обработка нейроном входных признаков происходит пропусканием взвешенной суммы через нелинейную функцию, называемую функцией активации\\
   \begin{equation}\label{eq:sum_mp}
   y(x) = \phi(\sum_{j=1}^{n}w_{j}x_{j})
   \end{equation}
	\indent В качестве нейлинейной фунцкии, наиболее популярным выбором является сигмоидальная функция\cite{Zaencev1999}. Данная функция удобна своей непрерывностью и гладкостью, и позволяет ограничить выход нейрона  отрезком значений $y(x)\in[0,1]$, такой выход можно интерпретировать как уровень активации нейрона, в зависимости от входного вектора $x$ и настройки весов $w$, что имеет свою, пускай и отдаленную, биологическую подоплёку. \\
   \indent Не смотря на ошеломляющий успех и широкое применения данной модели  и производных в прикладных задачах, с биологической точки зрения такие нейроны, только отдаленно напоминают, то как работают настоящие нейроны в мозгу.\\
   \indent Важным отличием такого нейрона от биологического является тот факт, что данная модель не имеет внутреннего состояния и не может быть представлена в виде динамической системы\cite{Zaencev1999}. Данное свойство серьезно ограничивает круг задач в которых можно было бы применить нейронные сети. 

\subsubsection{Модель Ходжкина-Хаксли}
	В 1952 году Алан Ллойд Ходжкин и Эндрю Хаксли разработали первую, наиболее подробную, на тот момент, математическую модель нейрона. Модель была построена на основе динамики генерации и передачи нервного сигнала в гигантcком аксоне кальмара.\\
	\indent Общая динамика потенциала нейрона описывается плавным затуханием значения потенциала $V_{m}$, со скоростью, которая характеризуется ёмкостью мембраны клетки $C_{m}$
	\begin{equation}\label{eq:hh}
	C_{m}\frac{dV_{m}}{dt}+I_{ion}=I_{ext}
	\end{equation}	 
	здесь $I_{ion}$ - сумма ионных токов внутри клетки, $I_{ext}$ - приложенный ток снаружи клетки.\\
	\indent Сложность уравнения \ref{eq:hh} таится в моделировании ионных токов для каждого типа ионов. В модели Ходжкина-Хаксли динамика ионных токов характеризуется наличием т.н. ионных каналов, открытие или закрытие которых влияет на общую динамику напряжения на мембране. В исходной модели Ходжкина-Хаксли было два вида ионов $Na^{+}$ и $K^{-}$, где ионный поток $Na^{+}$ описывается тремя каналами $m$ и одним каналом $h$, ионный поток $K^{-}$ описывается четырьмя каналами $n$, где $m, h, n$ - вероятности открытия соответствующего канала\cite{Genesis}.\\ 
	\indent Динамика вероятности открытия-закрытия каналов, описывается дифференциальным уравнением первого порядка
	\begin{equation}\label{eq:hh_pch}
	\frac{dp_{i}}{dt} = \alpha_{i}(V)(1-p_{i}) - \beta_{i}(V)p_{i}
	\end{equation}	 
	где $\alpha_{i}(V), \beta_{i}(V)$ константы зависящие от напряжения мембраны, которые характеризуют скорость закрытия и открытия канала, соответственно. Временной промежуток, спустя который вероятность достигает равновесия, описывается константой
	\begin{equation}\label{eq:hh_t}
	\tau_{i}=\frac{1}{\alpha_{i}(V)+\beta_{i}(V)}	
	\end{equation}
	\indent Таким образом динамику ионных токов для модели Ходжкина-Хаксли, можно описать
	\begin{equation}\label{eq:hh_ion}
	I_{ion} = \bar{g}_{Na}m^{3}h(V_{m}-E_{Na}) + \bar{g}_{K}n^{4}(V_{m}-E_{K})+\bar{g}_{L}(V_{m}-E_{L})
	\end{equation}	
	где $m, h, n$ - вероятности открытия каналов, описываются уравнением динамики \ref{eq:hh_pch}, которые включают соответствующие константы. Константы нормировки $\bar{g}$ и другие можно найти в оригинальной работе\cite{HH}.\\
	\indent Не смотря на то, что применение такой модели в задачах машинного обучения затруднительно, ввиду её сложности, эта модель имеет свою важную как  научную так и историческую роль.

\subsection{Формальные спайковые модели}   
\indent Нейронные модели описанные в данной секции принадлежат к семейству формальных моделей. Простота этих моделей позволяет перейти от анализа одного-двух нейронов к анализу популяций нейронов соединённых в сети, опуская биологическую точность, но сохраняя общие черты характерные для спайковых моделей.\\
\subsubsection{Модель Integrate-and-Fire}

\indent Упрощение модели Ходжкина-Хаксли, до динамической системы с одной переменной, проще моделировать, но, такая модель повторяет только части динамики биологических нейронов.

\subsubsection{Модель Ижикевича}
Модель нейрона в виде динамической системы с двумя переменными, довольно проста и в то же время имеет богатую динамику. Модель является компромиссом между упрощенной моделью IaF и HH. 

\subsubsection{Spike Response Model}
Отдельным рядом стоит модель SRM, в своём оригинальном виде модель повторяет IaF, но в своей формулировке наиболее удобна для теоретического исследования. Наиболее часто эту модель используют со   стохастическим порогом, который позволяет процесс генерации спайка описать негомогенным пуассоновским процессом.

\subsubsection{Spike Response Model с адаптацией}
Усложнение модели SRM, которая повторяет феномен адаптации.

\section{Обучение с учителем и без учителя}
\subsection{Классическое правило Хэбба}
\subsection{Обучение на основе градиента ошибки}
\subsection{Обучение на основе феноменологической модели STDP}
\subsection{Теоретическая оптимальная модель STDP}
\section{Обучение с подкреплением}
\subsection{Трехфакторное правило обучения}
\subsection{Гедонистический синапс}
\subsection{Обучение на основе TD-ошибки}
\section{Выводы}
\section{Использованная литература}
\bibliography{refs}{}
\bibliographystyle{unsrt}

\end{document}
