{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "np.seterr('raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FIG_SIZE = (15, 10)\n",
    "\n",
    "def plot_wrapper(fn):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        ncols = kwargs.get(\"ncols\", 1)\n",
    "        id = kwargs.get(\"id\", 0)\n",
    "        nrows = len(args)\n",
    "\n",
    "        if id == 0:\n",
    "            plt.figure(figsize=kwargs.get(\"figsize\", DEFAULT_FIG_SIZE))\n",
    "\n",
    "        for a_id, a in enumerate(args):\n",
    "            plt.subplot(nrows, ncols, nrows*id + a_id+1)\n",
    "            fn(a, **kwargs)\n",
    "\n",
    "        if kwargs.get(\"file\"):\n",
    "            plt.savefig(kwargs[\"file\"])\n",
    "            plt.clf()\n",
    "        elif kwargs.get(\"show\", True) and id+1 == ncols:\n",
    "            plt.show()\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "@plot_wrapper\n",
    "def shm(matrix, **kwargs):\n",
    "    plt.imshow(np.squeeze(matrix).T, cmap='gray', origin='lower')\n",
    "    plt.colorbar()\n",
    "    \n",
    "def shl(*vector, **kwargs):\n",
    "    plt.figure(figsize=kwargs.get(\"figsize\", DEFAULT_FIG_SIZE))\n",
    "    \n",
    "    labels = kwargs.get(\"labels\", [])\n",
    "    for id, v in enumerate(vector):\n",
    "        if len(labels) > 0:\n",
    "            plt.plot(np.squeeze(v), label=labels[id])\n",
    "        else:\n",
    "            plt.plot(np.squeeze(v))\n",
    "\n",
    "    if len(labels) > 0:\n",
    "        plt.legend()\n",
    "    \n",
    "    if not kwargs.get(\"title\") is None:\n",
    "        plt.suptitle(kwargs[\"title\"])\n",
    "\n",
    "    if kwargs.get(\"file\"):\n",
    "        plt.savefig(kwargs[\"file\"])\n",
    "        plt.clf()\n",
    "    elif kwargs.get(\"show\", True):\n",
    "        plt.show()\n",
    "\n",
    "relu = lambda x: np.maximum(x, 0.0)\n",
    "relu_prime = lambda x: np.where(x > 0.0, 1.0, 0.0)\n",
    "\n",
    "sigmoid = lambda x: 1.0/(1.0 + np.exp(-x))\n",
    "def sigmoid_prime(x):\n",
    "    v = sigmoid(x)\n",
    "    return v * (1.0 - v)\n",
    "\n",
    "t_clip_value = 1.0\n",
    "\n",
    "threshold = lambda x: np.where(x > 0.0, 1.0, 0.0)\n",
    "threshold_prime = lambda x: np.where(threshold(x) <= t_clip_value, 1.0, 0.0)\n",
    "\n",
    "# def threshold_prime(x, threshold_value = 0.0):\n",
    "#     return 1.0/np.square(1.0 + np.abs(x - threshold_value))\n",
    "\n",
    "def one_hot_encode(target_v, size=None):\n",
    "    y_v = np.zeros((target_v.shape[0], size if not size is None else len(np.unique(target_v))))\n",
    "    for cl_id, cl_v in enumerate(np.unique(target_v)):\n",
    "        y_v[np.where(target_v==cl_v)[0], cl_id] = 1.0\n",
    "\n",
    "    return y_v\n",
    "\n",
    "def weights_init(fan_in, fan_out, const=1.0):\n",
    "    low = -const * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    high = const * np.sqrt(6.0 / (fan_in + fan_out))\n",
    "    return (\n",
    "        (low + np.random.random((fan_in, fan_out)) * (high - low)).astype(np.float32),\n",
    "        (low + np.random.random((fan_out,)) * (high - low)).astype(np.float32)\n",
    "    )\n",
    "\n",
    "def number_of_equal_act(a, a_t):\n",
    "    a_t_m = a_t.copy()\n",
    "    a_t_m[np.where(np.abs(a_t_m) < 1e-10)] = -1\n",
    "\n",
    "    a_m = a.copy()\n",
    "    a_m[np.where(np.abs(a_m) < 1e-10)] = -10\n",
    "\n",
    "    a_t_mean = np.mean(a_t)\n",
    "    if a_t_mean == 0.0:\n",
    "        if np.mean(np.equal(a_t_m, a_m)) == 0.0:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "    else:\n",
    "        return np.mean(np.equal(a_t_m, a_m)) / np.mean(a_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, 11.358\n",
      "Epoch 50, 0.000\n",
      "Epoch 100, 0.000\n",
      "Epoch 150, 0.000\n",
      "Epoch 200, 0.000\n",
      "Epoch 250, 0.000\n",
      "Epoch 300, 0.000\n",
      "Epoch 350, 0.000\n",
      "Epoch 400, 0.000\n",
      "Epoch 450, 0.000\n",
      "Epoch 499, 0.000\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(1)\n",
    "\n",
    "input_dim = 20\n",
    "output_dim = 3\n",
    "batch_size = 100\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "# f, f_prime = sigmoid, sigmoid_prime\n",
    "f, f_prime = threshold, threshold_prime\n",
    "\n",
    "W_orig, _ = weights_init(input_dim, output_dim)\n",
    "\n",
    "X = (np.random.random((batch_size, input_dim)) < 0.1).astype(np.float32)\n",
    "Yt = f(np.dot(X, W_orig))\n",
    "\n",
    "W, _ = weights_init(input_dim, output_dim)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    u = np.dot(X, W)\n",
    "    y = f(u)\n",
    "    \n",
    "    e = Yt - y\n",
    "    \n",
    "    dW = np.dot(X.T, e)\n",
    "    \n",
    "    W += learning_rate * dW\n",
    "    \n",
    "    if (epoch % (epochs // 10)) == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "        print(\"Epoch {}, {:.3f}\".format(epoch, np.linalg.norm(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, 1.732\n",
      "Epoch 50, 2.000\n",
      "Epoch 100, 2.000\n",
      "Epoch 150, 2.000\n",
      "Epoch 200, 2.000\n",
      "Epoch 250, 2.000\n",
      "Epoch 300, 2.000\n",
      "Epoch 350, 2.000\n",
      "Epoch 400, 2.000\n",
      "Epoch 450, 2.000\n",
      "Epoch 499, 2.000\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(1)\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 2\n",
    "batch_size = 4\n",
    "epochs = 500\n",
    "learning_rate = 0.01\n",
    "\n",
    "# f, f_prime = sigmoid, sigmoid_prime\n",
    "f, f_prime = threshold, threshold_prime\n",
    "\n",
    "X = np.asarray([\n",
    "    [0.0, 0.0],\n",
    "    [0.0, 1.0],\n",
    "    [1.0, 0.0],\n",
    "    [1.0, 1.0]\n",
    "], dtype=np.float32)\n",
    "Yt = one_hot_encode(np.asarray([\n",
    "    [0.0],\n",
    "    [1.0],\n",
    "    [1.0],\n",
    "    [0.0]\n",
    "], dtype=np.float32), 2)\n",
    "\n",
    "\n",
    "W, _ = weights_init(input_dim, output_dim)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    u = np.dot(X, W)\n",
    "    y = f(u)\n",
    "    \n",
    "    e = Yt - y\n",
    "    \n",
    "    dW = np.dot(X.T, e)\n",
    "    \n",
    "    W += learning_rate * dW\n",
    "    \n",
    "    if (epoch % (epochs // 10)) == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "        print(\"Epoch {}, {:.3f}\".format(epoch, np.linalg.norm(e)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, |e| 24.225 |et| 20.273 |du0| 102.678 |num.eq| 72.612%\n",
      "Epoch 200, |e| 13.186 |et| 15.524 |du0| 4.356 |num.eq| 83.424%\n",
      "Epoch 400, |e| 11.890 |et| 15.330 |du0| 2.977 |num.eq| 83.740%\n",
      "Epoch 600, |e| 11.758 |et| 15.067 |du0| 2.119 |num.eq| 83.644%\n",
      "Epoch 800, |e| 11.239 |et| 14.731 |du0| 1.517 |num.eq| 85.054%\n",
      "Epoch 1000, |e| 11.227 |et| 14.697 |du0| 1.061 |num.eq| 84.148%\n",
      "Epoch 1200, |e| 11.283 |et| 15.067 |du0| 0.949 |num.eq| 83.733%\n",
      "Epoch 1400, |e| 11.038 |et| 14.967 |du0| 0.924 |num.eq| 83.798%\n",
      "Epoch 1600, |e| 10.951 |et| 14.832 |du0| 0.441 |num.eq| 84.522%\n",
      "Epoch 1800, |e| 10.828 |et| 14.663 |du0| 0.441 |num.eq| 85.000%\n",
      "Epoch 1999, |e| 10.862 |et| 15.166 |du0| 0.341 |num.eq| 84.690%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# f, f_prime = sigmoid, sigmoid_prime\n",
    "f, f_prime = threshold, threshold_prime\n",
    "\n",
    "W_orig_0 = np.random.randn(20, 100)\n",
    "W_orig_1 = np.random.randn(100, 10)\n",
    "\n",
    "# train data\n",
    "X = (np.random.random((2000, 20)) < 0.1).astype(np.float32)\n",
    "Y = f(np.dot(f(np.dot(X, W_orig_0)), W_orig_1))\n",
    "\n",
    "# test data\n",
    "Xt = (np.random.random((200, 20)) < 0.1).astype(np.float32)\n",
    "Yt = f(np.dot(f(np.dot(Xt, W_orig_0)), W_orig_1))\n",
    "\n",
    "# Xt, Yt = X, Y\n",
    "\n",
    "# X = np.asarray([\n",
    "#     [0.0, 0.0],\n",
    "#     [0.0, 1.0],\n",
    "#     [1.0, 0.0],\n",
    "#     [1.0, 1.0]\n",
    "# ], dtype=np.float32)\n",
    "# Yt = one_hot_encode(np.asarray([\n",
    "#     [0.0],\n",
    "#     [1.0],\n",
    "#     [1.0],\n",
    "#     [0.0]\n",
    "# ], dtype=np.float32), 2)\n",
    "\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = Yt.shape[1]\n",
    "batch_size = 200\n",
    "number_of_train_batches = X.shape[0] // batch_size\n",
    "number_of_test_batches = Xt.shape[0] // batch_size\n",
    "\n",
    "hidden_dim = 300\n",
    "epochs = 2000\n",
    "init_learning_rate = 0.0005\n",
    "\n",
    "W0, b0 = weights_init(input_dim, hidden_dim)\n",
    "W1, b1 = weights_init(hidden_dim, output_dim)\n",
    "W0_fb, b0_fb = weights_init(output_dim, hidden_dim)\n",
    "\n",
    "W0_start = W0.copy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permute_ids = np.random.permutation(X.shape[0])\n",
    "    X = X[permute_ids, :]\n",
    "    Y = Y[permute_ids, :]\n",
    "\n",
    "    e_avg, et_avg = 0.0, 0.0\n",
    "    du0_avg = 0.0\n",
    "    num_eq_avg = 0.0\n",
    "    learning_rate = (float(init_learning_rate) / (epoch + 1) ** 0.5)\n",
    "#     learning_rate = init_learning_rate * (1.0 - epoch / epochs)\n",
    "    for i in range(number_of_train_batches):\n",
    "        x = X[i*batch_size:(i+1)*batch_size,:]\n",
    "        y = Y[i*batch_size:(i+1)*batch_size,:]\n",
    "\n",
    "        u0 = np.dot(x, W0)\n",
    "        y0 = f(u0)\n",
    "\n",
    "        u1 = np.dot(y0, W1)\n",
    "        y1 = f(u1)\n",
    "\n",
    "        e = y - y1\n",
    "\n",
    "        y0_fb = f(np.dot(y, W0_fb)) \n",
    "\n",
    "        du1 = e\n",
    "#         du0 = np.dot(du1, W1.T) * f_prime(u0) # BP\n",
    "#         du0 = np.dot(du1, W0_fb) * f_prime(u0) # FA\n",
    "        du0 = (y0 * y0_fb - y0) * f_prime(u0)\n",
    "\n",
    "        dW1 = np.dot(y0.T, du1)\n",
    "        db1 = np.sum(du1, 0)\n",
    "\n",
    "        dW0 = np.dot(x.T, du0)\n",
    "        db0 = np.sum(du0, 0)\n",
    "\n",
    "        W0 += learning_rate * dW0\n",
    "        b0 += learning_rate * db0\n",
    "        W1 += learning_rate * dW1\n",
    "        b1 += learning_rate * db1\n",
    "        \n",
    "        e_avg += np.linalg.norm(e)\n",
    "        du0_avg += np.linalg.norm(du0)\n",
    "        \n",
    "    for i in range(number_of_test_batches):\n",
    "        xt = Xt[i*batch_size:(i+1)*batch_size,:]\n",
    "        yt = Yt[i*batch_size:(i+1)*batch_size,:]\n",
    "\n",
    "        yt0 = f(np.dot(xt, W0))\n",
    "        yt1 = f(np.dot(yt0, W1))\n",
    "\n",
    "        et = yt - yt1\n",
    "        et_avg += np.linalg.norm(et)\n",
    "        num_eq_avg += number_of_equal_act(yt, yt1)\n",
    "        \n",
    "    if (epoch % (epochs // 10)) == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "        print(\"Epoch {}, |e| {:.3f} |et| {:.3f} |du0| {:.3f} |num.eq| {:.3f}%\".format(\n",
    "            epoch, \n",
    "            e_avg /  number_of_train_batches,\n",
    "            et_avg /  number_of_test_batches,\n",
    "            du0_avg /  number_of_train_batches,\n",
    "            100.0 * num_eq_avg / number_of_test_batches,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, |e| 22.602 |et| 21.541 |du0| 95.123 |du1| 23.305 |num.eq| 75.660%\n",
      "Epoch 200, |e| 15.957 |et| 17.916 |du0| 5.210 |du1| 2.540 |num.eq| 83.943%\n",
      "Epoch 400, |e| 16.766 |et| 17.607 |du0| 3.694 |du1| 1.921 |num.eq| 83.514%\n",
      "Epoch 600, |e| 16.243 |et| 17.234 |du0| 3.059 |du1| 1.789 |num.eq| 85.670%\n",
      "Epoch 800, |e| 15.920 |et| 17.117 |du0| 2.538 |du1| 1.089 |num.eq| 84.320%\n",
      "Epoch 1000, |e| 16.222 |et| 17.146 |du0| 2.151 |du1| 1.111 |num.eq| 83.836%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "# f, f_prime = sigmoid, sigmoid_prime\n",
    "f, f_prime = threshold, threshold_prime\n",
    "\n",
    "W_orig_0 = np.random.randn(20, 100)\n",
    "W_orig_1 = np.random.randn(100, 100)\n",
    "W_orig_2 = np.random.randn(100, 10)\n",
    "\n",
    "# train data\n",
    "X = (np.random.random((2000, 20)) < 0.1).astype(np.float32)\n",
    "Y = f(np.dot(f(np.dot(f(np.dot(X, W_orig_0)), W_orig_1)), W_orig_2))\n",
    "\n",
    "# test data\n",
    "Xt = (np.random.random((200, 20)) < 0.1).astype(np.float32)\n",
    "Yt = f(np.dot(f(np.dot(f(np.dot(Xt, W_orig_0)), W_orig_1)), W_orig_2))\n",
    "\n",
    "# Xt, Yt = X, Y\n",
    "\n",
    "# X = np.asarray([\n",
    "#     [0.0, 0.0],\n",
    "#     [0.0, 1.0],\n",
    "#     [1.0, 0.0],\n",
    "#     [1.0, 1.0]\n",
    "# ], dtype=np.float32)\n",
    "# Yt = one_hot_encode(np.asarray([\n",
    "#     [0.0],\n",
    "#     [1.0],\n",
    "#     [1.0],\n",
    "#     [0.0]\n",
    "# ], dtype=np.float32), 2)\n",
    "\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = Yt.shape[1]\n",
    "batch_size = 200\n",
    "number_of_train_batches = X.shape[0] // batch_size\n",
    "number_of_test_batches = Xt.shape[0] // batch_size\n",
    "\n",
    "hidden_dim = 300\n",
    "epochs = 2000\n",
    "init_learning_rate = 0.0005\n",
    "\n",
    "W0, b0 = weights_init(input_dim, hidden_dim)\n",
    "W1, b1 = weights_init(hidden_dim, hidden_dim)\n",
    "W2, b2 = weights_init(hidden_dim, output_dim)\n",
    "W0_fb, b0_fb = weights_init(hidden_dim, hidden_dim)\n",
    "W1_fb, b1_fb = weights_init(output_dim, hidden_dim)\n",
    "\n",
    "W0_start = W0.copy()\n",
    "W1_start = W1.copy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    permute_ids = np.random.permutation(X.shape[0])\n",
    "    X = X[permute_ids, :]\n",
    "    Y = Y[permute_ids, :]\n",
    "\n",
    "    e_avg, et_avg = 0.0, 0.0\n",
    "    du0_avg, du1_avg = 0.0, 0.0\n",
    "    num_eq_avg = 0.0\n",
    "    learning_rate = (float(init_learning_rate) / (epoch + 1) ** 0.5)\n",
    "#     learning_rate = init_learning_rate * (1.0 - epoch / epochs)\n",
    "    for i in range(number_of_train_batches):\n",
    "        x = X[i*batch_size:(i+1)*batch_size,:]\n",
    "        y = Y[i*batch_size:(i+1)*batch_size,:]\n",
    "\n",
    "        u0 = np.dot(x, W0)\n",
    "        y0 = f(u0)\n",
    "\n",
    "        u1 = np.dot(y0, W1)\n",
    "        y1 = f(u1)\n",
    "\n",
    "        u2 = np.dot(y1, W2)\n",
    "        y2 = f(u2)\n",
    "\n",
    "        e = y - y2\n",
    "\n",
    "        y1_fb = f(np.dot(y, W1_fb)) \n",
    "        y0_fb = f(np.dot(y1_fb, W0_fb)) \n",
    "\n",
    "        du2 = e\n",
    "        # BP\n",
    "#         du1 = np.dot(du2, W2.T) * f_prime(u1)\n",
    "#         du0 = np.dot(du1, W1.T) * f_prime(u0)\n",
    "        \n",
    "#         du0 = np.dot(du1, W0_fb) * f_prime(u0) # FA\n",
    "\n",
    "        # FB\n",
    "        du1 = (y1 * y1_fb - y1) * f_prime(u1)\n",
    "        du0 = (y0 * y0_fb - y0) * f_prime(u0)\n",
    "\n",
    "        dW2 = np.dot(y1.T, du2)\n",
    "        db2 = np.sum(du2, 0)\n",
    "\n",
    "        dW1 = np.dot(y0.T, du1)\n",
    "        db1 = np.sum(du1, 0)\n",
    "\n",
    "        dW0 = np.dot(x.T, du0)\n",
    "        db0 = np.sum(du0, 0)\n",
    "\n",
    "        W0 += learning_rate * dW0\n",
    "        b0 += learning_rate * db0\n",
    "        \n",
    "        W1 += learning_rate * dW1\n",
    "        b1 += learning_rate * db1\n",
    "\n",
    "        W2 += learning_rate * dW2\n",
    "        b2 += learning_rate * db2\n",
    "        \n",
    "        e_avg += np.linalg.norm(e)\n",
    "        du0_avg += np.linalg.norm(du0)\n",
    "        du1_avg += np.linalg.norm(du1)\n",
    "        \n",
    "    for i in range(number_of_test_batches):\n",
    "        xt = Xt[i*batch_size:(i+1)*batch_size,:]\n",
    "        yt = Yt[i*batch_size:(i+1)*batch_size,:]\n",
    "\n",
    "        yt0 = f(np.dot(xt, W0))\n",
    "        yt1 = f(np.dot(yt0, W1))\n",
    "        yt2 = f(np.dot(yt1, W2))\n",
    "\n",
    "        et = yt - yt2\n",
    "        et_avg += np.linalg.norm(et)\n",
    "        num_eq_avg += number_of_equal_act(yt, yt2)\n",
    "        \n",
    "    if (epoch % (epochs // 10)) == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "        print(\"Epoch {}, |e| {:.3f} |et| {:.3f} |du0| {:.3f} |du1| {:.3f} |num.eq| {:.3f}%\".format(\n",
    "            epoch, \n",
    "            e_avg /  number_of_train_batches,\n",
    "            et_avg /  number_of_test_batches,\n",
    "            du0_avg /  number_of_train_batches,\n",
    "            du1_avg /  number_of_train_batches,\n",
    "            100.0 * num_eq_avg / number_of_test_batches,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, |e| 21.932 |du0| 82.480 |du1| 81.240\n",
      "Epoch 20, |e| 14.036 |du0| 35.071 |du1| 5.916\n",
      "Epoch 40, |e| 11.874 |du0| 17.607 |du1| 3.000\n",
      "Epoch 60, |e| 9.381 |du0| 9.747 |du1| 2.000\n",
      "Epoch 80, |e| 8.832 |du0| 6.325 |du1| 2.236\n",
      "Epoch 100, |e| 6.481 |du0| 3.162 |du1| 0.000\n",
      "Epoch 120, |e| 3.464 |du0| 0.000 |du1| 0.000\n",
      "Epoch 140, |e| 0.000 |du0| 0.000 |du1| 0.000\n",
      "Epoch 160, |e| 0.000 |du0| 0.000 |du1| 0.000\n",
      "Epoch 180, |e| 0.000 |du0| 0.000 |du1| 0.000\n",
      "Epoch 199, |e| 0.000 |du0| 0.000 |du1| 0.000\n"
     ]
    }
   ],
   "source": [
    "# np.random.seed(10)\n",
    "\n",
    "# f, f_prime = sigmoid, sigmoid_prime\n",
    "f, f_prime = threshold, threshold_prime\n",
    "\n",
    "W_orig_0 = np.random.randn(20, 100)\n",
    "W_orig_1 = np.random.randn(100, 100)\n",
    "W_orig_2 = np.random.randn(100, 10)\n",
    "X = (np.random.random((100, 20)) < 0.1).astype(np.float32)\n",
    "Yt = f(np.dot(f(np.dot(f(np.dot(X, W_orig_0)), W_orig_1)), W_orig_2))\n",
    "\n",
    "# X = np.asarray([\n",
    "#     [0.0, 0.0],\n",
    "#     [0.0, 1.0],\n",
    "#     [1.0, 0.0],\n",
    "#     [1.0, 1.0]\n",
    "# ], dtype=np.float32)\n",
    "# Yt = one_hot_encode(np.asarray([\n",
    "#     [0.0],\n",
    "#     [1.0],\n",
    "#     [1.0],\n",
    "#     [0.0]\n",
    "# ], dtype=np.float32), 2)\n",
    "\n",
    "\n",
    "input_dim = X.shape[1]\n",
    "output_dim = Yt.shape[1]\n",
    "batch_size = X.shape[0]\n",
    "\n",
    "hidden_dim = 300\n",
    "epochs = 200\n",
    "learning_rate = 0.001\n",
    "\n",
    "W0, b0 = weights_init(input_dim, hidden_dim)\n",
    "W1, b1 = weights_init(hidden_dim, hidden_dim)\n",
    "W2, b2 = weights_init(hidden_dim, output_dim)\n",
    "W0_fb, b0_fb = weights_init(hidden_dim, hidden_dim)\n",
    "W1_fb, b1_fb = weights_init(output_dim, hidden_dim)\n",
    "\n",
    "W0_start = W0.copy()\n",
    "W1_start = W1.copy()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    u0 = np.dot(X, W0)\n",
    "    y0 = f(u0)\n",
    "\n",
    "    u1 = np.dot(y0, W1)\n",
    "    y1 = f(u1)\n",
    "\n",
    "    u2 = np.dot(y1, W2)\n",
    "    y2 = f(u2)\n",
    "    \n",
    "    e = Yt - y2\n",
    "    \n",
    "    y1_fb = f(np.dot(Yt, W1_fb)) \n",
    "    y0_fb = f(np.dot(y1_fb, W0_fb)) \n",
    "    \n",
    "    du2 = e\n",
    "    du0 = np.dot(du1, W1.T) * f_prime(u0) # BP\n",
    "    du0 = np.dot(du1, W0_fb) * f_prime(u0) # FA\n",
    "    \n",
    "    du1 = (y1 * y1_fb - y1)# * f_prime(u1)\n",
    "    du0 = (y0 * y0_fb - y0)# * f_prime(u0)\n",
    "\n",
    "    dW2 = np.dot(y1.T, du2)\n",
    "    db2 = np.sum(du2, 0)\n",
    "    \n",
    "    dW1 = np.dot(y0.T, du1)\n",
    "    db1 = np.sum(du1, 0)\n",
    "    \n",
    "    dW0 = np.dot(X.T, du0)\n",
    "    db0 = np.sum(du0, 0)\n",
    "    \n",
    "    W0 += learning_rate * dW0\n",
    "    b0 += learning_rate * db0\n",
    "    W1 += learning_rate * dW1\n",
    "    b1 += learning_rate * db1\n",
    "    W2 += learning_rate * dW2\n",
    "    b2 += learning_rate * db2\n",
    "\n",
    "    if (epoch % (epochs // 10)) == 0 or epoch == 0 or epoch == epochs - 1:\n",
    "        print(\"Epoch {}, |e| {:.3f} |du0| {:.3f} |du1| {:.3f}\".format(\n",
    "            epoch, \n",
    "            np.linalg.norm(e), \n",
    "            np.linalg.norm(du0),\n",
    "            np.linalg.norm(du1)\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
